<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-03-12T23:19:52-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">antounes’ blog</title><subtitle>Data science @ Jellyfish </subtitle><author><name>Matthieu Brito Antunes</name></author><entry><title type="html">ML, a short story</title><link href="http://localhost:4000/posts/2021/01/blog-post-1/" rel="alternate" type="text/html" title="ML, a short story" /><published>2021-01-26T00:00:00-08:00</published><updated>2021-01-26T00:00:00-08:00</updated><id>http://localhost:4000/posts/2021/01/ml-a-short-story</id><content type="html" xml:base="http://localhost:4000/posts/2021/01/blog-post-1/">&lt;p&gt;ML stands for &lt;em&gt;Machine Learning&lt;/em&gt; and is a sub-field of AI, or &lt;em&gt;Artificial Intelligence&lt;/em&gt;, centered around how computers learn from
data. Nowadays the expression has become familiar to anyone dealing with data related subjects. Sometimes it’s even 
the first considered tool for solving problems, even if it’s not always the most appropriate.&lt;br /&gt;
This post gives a quick overview of the history of ML, its basic principles, how it was first unconsidered and how it
finally became the powerful machinery we hear about today.&lt;/p&gt;

&lt;h2 id=&quot;think-like-turing&quot;&gt;Think like Turing&lt;/h2&gt;

&lt;p&gt;In 1950 Alan Turing published his article &lt;em&gt;Computing Machinery and Intelligence&lt;/em&gt; in the quarterly review of philosophy 
&lt;em&gt;Mind&lt;/em&gt; and asked the fundamental question: “Can machines think ?”. As the first article to introduce the concept of what
is now known as the Turing test, this represented the foundation of artificial intelligence. From there on, a variety of
dedicated labs and research teams bud across the world.&lt;br /&gt;
In the mid-1950’s, with access to more sophisticated computers became possible, researchers began to look for a way of 
reproducing human reasoning. Most of the research was carried out in the US, mainly gravitating around three centers: 
Stanford, Carnegie Mellon University and the MIT. AI practitioners were quite optimistic about the future.&lt;/p&gt;

&lt;h2 id=&quot;ai-winter&quot;&gt;AI Winter&lt;/h2&gt;

&lt;p&gt;First wrong note arose in the late 1960’s with the acknowledgement of failure of machine translation. The goal was to
investigate capabilities of software to translate text or speech from a language to another. This one was the first of 
a series of episodes that would lead to the first major period of reduced interest in artificial intelligence research.
The Lighthill report, dating from 1974, made evidence of the failure of artificial intelligence to reach its objectives.
AI research was consequently dismantled in the UK, and the winter also hurt the research in the US.&lt;/p&gt;

&lt;h2 id=&quot;a-brief-revival&quot;&gt;A brief revival&lt;/h2&gt;

&lt;p&gt;In the early 1980’s, the development of expert systems aimed at mimicking human ability to make decisions on subjects 
requiring expertise. First successful expert systems were developed at Carnegie Mellon university, and their early 
adoption led to a renewal of interest in research on artificial intelligence.&lt;br /&gt;
Things didn’t go well for very long though. During the 1980’s, emerging LISP machines were developed for processing the
LISP programming language, the preferred language for AI at the time. These machines were surpassed by more powerful 
alternatives, and the market collapsed. This episode marked the beginning of the second AI Winter.&lt;/p&gt;

&lt;h2 id=&quot;success-specialisation-and-spread&quot;&gt;Success, specialisation and spread&lt;/h2&gt;

&lt;p&gt;In the late 1990’s, the increases in computational power, and the links made with other research fields such as Statistics,
Economics and Mathematics were at the origin of a greater interest in practical AI. Tools began to be used for data mining,
medical diagnosis, logistics, and other areas.&lt;br /&gt;
AI became a highly specialised field, with researchers putting more emphasis on solving specific problems, defining proper
standards and using scientific and mathematical principles. The first great success of this reborn AI was obtained in
1997, with the victory of IBM’s Deep Blue chess-playing computer system against Russian reigning champion Gary Kasparov.&lt;br /&gt;
From there on, a real need for establishing the theoretical foundations and defining basic principles was stated. Vladimir
Vapnik’s &lt;em&gt;Statistical Learning Theory&lt;/em&gt; was published in 1995 and is still a reference when it comes to defining ML 
fundamentals.&lt;/p&gt;</content><author><name>Matthieu Brito Antunes</name></author><category term="history" /><category term="machine-learning" /><summary type="html">ML stands for Machine Learning and is a sub-field of AI, or Artificial Intelligence, centered around how computers learn from data. Nowadays the expression has become familiar to anyone dealing with data related subjects. Sometimes it’s even the first considered tool for solving problems, even if it’s not always the most appropriate. This post gives a quick overview of the history of ML, its basic principles, how it was first unconsidered and how it finally became the powerful machinery we hear about today.</summary></entry></feed>